{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Union\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'cat_id',\n",
    "            'state_id',\n",
    "            'dept_id',\n",
    "            'store_id',\n",
    "            'item_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        group_ids = []\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            group_ids.append(group_id)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return group_ids, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public LB rank\n",
    "def get_lb_rank(score):\n",
    "    \"\"\"\n",
    "    Get rank on public LB as of 2020-05-31 23:59:59\n",
    "    \"\"\"\n",
    "    df_lb = pd.read_csv(\"m5-forecasting-accuracy-publicleaderboard.csv\")\n",
    "\n",
    "    return (df_lb.Score <= score).sum() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full = pd.read_csv(\"sales_train_evaluation.csv\")\n",
    "#df_train_full.iloc[:, -31:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:56<00:00,  9.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "df_calendar = pd.read_csv(\"calendar.csv\")\n",
    "df_prices = pd.read_csv(\"sell_prices.csv\")\n",
    "df_sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "df_train = df_train_full.iloc[:, :-28]\n",
    "df_valid = df_train_full.iloc[:, -28:]\n",
    "\n",
    "evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>d_1921</th>\n",
       "      <th>d_1922</th>\n",
       "      <th>d_1923</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>45</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>91</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>61</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>99</td>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>97</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1914  d_1915  d_1916  d_1917  d_1918  d_1919  d_1920  d_1921  d_1922  \\\n",
       "0      97      45      78       5       2      93      85      59      23   \n",
       "1       7      58      19       1      21      11      81      35      21   \n",
       "2      80      86      48       8      54      44      80      34      95   \n",
       "3      22       6      10     101      50      27      85      29      46   \n",
       "4      13      58      56      64      52      75      85      19      46   \n",
       "\n",
       "   d_1923  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  \\\n",
       "0      27  ...      83      41      71      38      86      97      32   \n",
       "1      60  ...      11      61      18      59      91      48      17   \n",
       "2      14  ...      46      86      25      72      78      37      17   \n",
       "3      24  ...      96      35      37      17      58      76      39   \n",
       "4      11  ...      18      70       0      89       1      40      97   \n",
       "\n",
       "   d_1939  d_1940  d_1941  \n",
       "0      45      17      90  \n",
       "1      32      21      89  \n",
       "2      61      97      25  \n",
       "3      99      44      78  \n",
       "4      54      55      47  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## structure of validation data\n",
    "preds_valid = df_valid.copy() + np.random.randint(100, size = df_valid.shape)\n",
    "preds_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 254.57438\n",
      "Score for group cat_id: 265.84406\n",
      "Score for group state_id: 232.46605\n",
      "Score for group dept_id: 265.87278\n",
      "Score for group store_id: 221.55892\n",
      "Score for group item_id: 82.2403\n",
      "Score for group ['state_id', 'cat_id']: 236.18121\n",
      "Score for group ['state_id', 'dept_id']: 231.83764\n",
      "Score for group ['store_id', 'cat_id']: 212.5632\n",
      "Score for group ['store_id', 'dept_id']: 198.52204\n",
      "Score for group ['item_id', 'state_id']: 51.5903\n",
      "Score for group ['item_id', 'store_id']: 31.26827\n",
      "\n",
      "Public LB Score: 190.3766\n",
      "Public LB Rank: 19291\n"
     ]
    }
   ],
   "source": [
    "## evaluating random submission\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 1.31903\n",
      "Score for group cat_id: 1.34048\n",
      "Score for group state_id: 1.26004\n",
      "Score for group dept_id: 1.35873\n",
      "Score for group store_id: 1.24401\n",
      "Score for group item_id: 0.96665\n",
      "Score for group ['state_id', 'cat_id']: 1.26701\n",
      "Score for group ['state_id', 'dept_id']: 1.27439\n",
      "Score for group ['store_id', 'cat_id']: 1.22063\n",
      "Score for group ['store_id', 'dept_id']: 1.20126\n",
      "Score for group ['item_id', 'state_id']: 0.91097\n",
      "Score for group ['item_id', 'store_id']: 0.87103\n",
      "\n",
      "Public LB Score: 1.18619\n",
      "Public LB Rank: 17078\n"
     ]
    }
   ],
   "source": [
    "## evaluating submission from public kernel M5 - Three shades of Dark: Darker magic\n",
    "## from https://www.kaggle.com/kyakovlev/m5-three-shades-of-dark-darker-magic\n",
    "preds_valid = pd.read_csv(\"submission1.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.79067\n",
      "Score for group cat_id: 3.05486\n",
      "Score for group state_id: 0.94786\n",
      "Score for group dept_id: 3.2932\n",
      "Score for group store_id: 1.47251\n",
      "Score for group item_id: 2.21258\n",
      "Score for group ['state_id', 'cat_id']: 2.74742\n",
      "Score for group ['state_id', 'dept_id']: 3.06133\n",
      "Score for group ['store_id', 'cat_id']: 2.6854\n",
      "Score for group ['store_id', 'dept_id']: 2.89827\n",
      "Score for group ['item_id', 'state_id']: 1.68166\n",
      "Score for group ['item_id', 'store_id']: 1.2811\n",
      "\n",
      "Public LB Score: 2.17724\n",
      "Public LB Rank: 18126\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.read_csv(\"submission4.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
